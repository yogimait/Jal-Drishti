import time
from app.video.video_reader import RawVideoSource

class FrameScheduler:
    def __init__(self, video_source: RawVideoSource, target_fps: int = 15, simulate_processing_delay: float = 0.0, 
                 ml_module = None, result_callback = None, raw_callback = None):
        """
        Initializes the FrameScheduler.

        Args:
            video_source (RawVideoSource): Instance of video source.
            target_fps (int): Target frames per second. Default 15.
            simulate_processing_delay (float): Artificial delay in seconds if no ML module is present.
            ml_module (object): Optional ML module with run_inference method.
            result_callback (callable): Optional callback for ML results. signature: (dict) -> None.
            raw_callback (callable): Optional callback for RAW frames. signature: (frame, frame_id, timestamp) -> None.
        """
        self.video_source = video_source
        self.target_fps = target_fps
        self.frame_interval = 1.0 / target_fps
        self.simulate_processing_delay = simulate_processing_delay
        self.ml_module = ml_module
        self.result_callback = result_callback
        self.raw_callback = raw_callback

    def run(self):
        """
        Runs the scheduler loop.
        Reads frames from the video reader, emits raw frames, enforces FPS, and handles logical drops.
        """
        print(f"[Scheduler] Starting at Target FPS={self.target_fps}, Interval={self.frame_interval:.4f}s")
        if self.ml_module:
            print("[Scheduler] ML Module detected. Using synchronous inference.")
        
        # SAFE MODE State
        self.in_safe_mode = False
        self.safe_mode_reason = None
        self.last_recovery_check = 0.0
        self.recovery_interval = 5.0 # Seconds
        
        start_time = time.time()
        frames_processed_in_window = 0
        last_fps_log_time = start_time
        current_fps = 0.0 # Store for payload

        # We iterate through all frames from the source
        try:
            # New contract: frame, frame_id, timestamp
            for frame, frame_id, timestamp in self.video_source.read():
                
                # Adjust start time reference if this is the first frame we see
                if frame_id == 0:
                    start_time = timestamp # Align scheduler clock with video timestamp
                
                current_time = time.time()
                # We use the provided timestamp if we want strictly video-time, 
                # but for real-time simulation, we check wall-clock drift against expected frame count.
                
                # Expected time since start
                expected_time = frame_id * self.frame_interval
                actual_elapsed = current_time - start_time
                
                # Drift check
                drift = actual_elapsed - expected_time
                
                # ALWAYS EMIT RAW FRAME (Decoupled from ML)
                if self.raw_callback:
                    # Non-blocking emission (presumed, depending on callback impl)
                    self.raw_callback(frame, frame_id, timestamp)

                if drift > self.frame_interval:
                    # We are behind by more than one frame. Drop this frame from ML processing.
                    print(f"[Scheduler] Frame {frame_id}: Status=DROPPED_FROM_ML (Drift={drift:.4f}s)")
                    continue # Skip ML
                else:
                    # Process the frame
                    # print(f"[Scheduler] Frame {frame_id}: Status=PROCESSED") # Reduce log spam
                    
                    # SAFE MODE CHECK / RECOVERY
                    should_run_ml = False
                    
                    if self.in_safe_mode:
                        # Periodically check for recovery
                        if current_time - self.last_recovery_check >= self.recovery_interval:
                            print("[Scheduler] Safe Mode: Attempting recovery check...")
                            should_run_ml = True # Try one inference
                            self.last_recovery_check = current_time
                        else:
                            # Skip ML, send Safe Mode status
                            if self.result_callback:
                                self.result_callback({
                                    "type": "system",
                                    "status": "safe_mode",
                                    "message": f"System in Safe Mode: {self.safe_mode_reason}",
                                    "payload": None
                                })
                    else:
                        should_run_ml = True # Normal operation

                    # ML PROCESSING
                    if self.ml_module and should_run_ml:
                        try:
                            # Blocking call to ML with timeout measurement
                            # print(f"[Scheduler] Frame {frame_id}: Sending to ML...")
                            
                            ml_start = time.time()
                            result = self.ml_module.run_inference(frame)
                            ml_end = time.time()
                            ml_duration = ml_end - ml_start
                            
                            # print(f"[Scheduler] Frame {frame_id}: ML Result Received. Duration={ml_duration:.4f}s")
                            
                            # CHECK FOR SLOW INFERENCE
                            if ml_duration > 0.2:
                                # We don't crash, just warn/safe mode if needed? 
                                # For now, let's just log. Strict requirement says "Support frame dropping under latency"
                                # We already drop frames if we drift.
                                pass
                            
                            # If we were in safe mode and succeeded quickly, recover
                            if self.in_safe_mode:
                                print(f"[Scheduler] Recovery Successful! (Duration: {ml_duration:.4f}s)")
                                self.in_safe_mode = False
                                self.safe_mode_reason = None
                                if self.result_callback:
                                    self.result_callback({
                                        "type": "system",
                                        "status": "recovered",
                                        "message": "System recovered",
                                        "payload": None
                                    })

                            # CALLBACK FOR WEBSOCKET (Normal Data)
                            if self.result_callback:
                                payload = result.copy()
                                payload['frame_id'] = frame_id
                                payload['system'] = {
                                    "fps": current_fps,
                                    "latency_ms": ml_duration * 1000
                                }
                                # Normal data format
                                self.result_callback({
                                    "type": "data",
                                    "status": "success",
                                    "message": "New frame data",
                                    "payload": payload
                                })

                        except Exception as e:
                            print(f"[Scheduler] Frame {frame_id}: ML Error: {e}")
                            
                            # ENTER SAFE MODE
                            if not self.in_safe_mode:
                                self.in_safe_mode = True
                                self.safe_mode_reason = str(e)
                                self.last_recovery_check = time.time() # Start timer
                                print(f"[Scheduler] !!! ENTERING SAFE MODE !!! Reason: {e}")
                                
                                if self.result_callback:
                                    self.result_callback({
                                        "type": "system",
                                        "status": "safe_mode",
                                        "message": str(e),
                                        "payload": None
                                    })
                                    
                    elif self.simulate_processing_delay > 0:
                        # Fallback simulation if no ML module
                        time.sleep(self.simulate_processing_delay)
                    
                    frames_processed_in_window += 1
                    
                    # Check if we processed too fast, need to sleep to maintain FPS
                    # But if we slept for ML, we probably don't need to sleep more.
                    # Re-calculate drift to sleep only if we are AHEAD.
                    post_process_time = time.time()
                    post_elapsed = post_process_time - start_time
                    next_frame_expected_time = (frame_id + 1) * self.frame_interval
                    
                    sleep_duration = next_frame_expected_time - post_elapsed
                    if sleep_duration > 0:
                        time.sleep(sleep_duration)

                # FPS Calculation (every 1 second)
                now = time.time()
                if now - last_fps_log_time >= 1.0:
                    current_fps = frames_processed_in_window # Update for payload
                    print(f"[Scheduler] actual_fps={frames_processed_in_window}, drift={drift:.3f}s")
                    frames_processed_in_window = 0
                    last_fps_log_time = now
        
        except Exception as e:
            # Catch unexpected Video loop errors
             print(f"[Scheduler] CRITICAL LOOP ERROR: {e}")
             import traceback
             traceback.print_exc()
             pass

if __name__ == "__main__":
    # Test Block
    from app.video.video_reader import RawVideoSource
    import sys
    
    print(f"Testing Scheduler...")
    source = RawVideoSource()
    scheduler = FrameScheduler(source, target_fps=15) 
    scheduler.run()
